---
title: "project_ds"
output:
  pdf_document: default
  html_document: default
  word_document: default
date: "2023-03-15"
---

# Project for DS
# Data analysis and sales prediction

# Load data and see the dataset
```{r message=FALSE, warning=FALSE, include=TRUE}
library(tidyverse)
library(modelr)
library(gridExtra)
library(reshape2)
library(dplyr)
library(ggplot2)
# Load data
data <- read_csv("Video_Games_Sales_as_at_22_Dec_2016.csv")
head(data)
```
# See the dataset discributions
```{r message=FALSE, warning=FALSE, include=TRUE}
sprintf('dataset size: [%s]', toString(dim(data)))
summary(data)

```
# See the missing data and the percent of missing data for each feature
```{r message=FALSE, warning=FALSE, include=TRUE}
missing_precent <- colMeans(is.na(data))*100
missing_precent
```
# See if there is any missing values and fill in the missing values
# Plot the count of missing values for features and sort them 
```{r message=FALSE, warning=FALSE, include=TRUE}
# count the missing the values 
missing <- data %>%
  gather(variable, value) %>%
  mutate(is_missing = is.na(value)) %>%
  group_by(variable, is_missing) %>%
  summarise(count = n()) %>%
  filter(is_missing) %>%
  arrange(desc(count))

# get the plot of missing alues for each feature
ggplot(missing, aes(x = reorder(variable, count), y = count, fill = count)) +
  geom_bar(stat = "identity") +
  
  labs(title = "Count of Missing Values for Each Feature",
       x = "Features",
       y = "Count of Missing Values")+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

# change the varible data types and get a new varible: Game Age based on the year of release
```{r message=FALSE, warning=FALSE, include=TRUE}
data$User_Score <- na_if(data$User_Score, 'N/A')
data$User_Score <- as.numeric(data$User_Score)
data$Year_of_Release <- as.numeric(data$Year_of_Release)
data$game_ages <- 2023-data$Year_of_Release
```

# Plot the distributions of the features with missing values,and then use the information to decide how to fill in the missing values
# plot the distrubtion of the numerical features
```{r message=FALSE, warning=FALSE, include=TRUE}

hist(data$User_Count)
hist(data$JP_Sales)
hist(data$Critic_Score)
hist(data$Critic_Count)
hist(data$User_Score)
hist(data$game_ages)
#column_names <- colnames(data)
#new_name <- gsub(' ', '_', column_names)
#new_name <- gsub('-', '_', new_name)
#colnames(data) <- new_name
#head(data)

```

# fill in with median: user_count, JP_sales, Critic_count, User_score
# fill in with mean critic_score, game_ages
```{r message=FALSE, warning=FALSE, include=TRUE}
mean_Critic_Score <- mean(data$Critic_Score, na.rm = TRUE)
mean_game_ages <- mean(data$game_ages, na.rm = TRUE)

data$Critic_Score <- ifelse(is.na(data$Critic_Score), mean_Critic_Score, data$Critic_Score)
#any_missing <- any(is.na(data$Adult_Mortality))
#print(any_missing)
data$game_ages <- ifelse(is.na(data$game_ages), mean_game_ages, data$game_ages)


median_User_Count <- median(data$User_Count, na.rm = TRUE)
median_JP_Sales <- median(data$JP_Sales, na.rm = TRUE)
median_Critic_Count <- median(data$Critic_Count, na.rm = TRUE)
median_User_Score <- median(data$User_Score, na.rm = TRUE)


data$User_Count <- ifelse(is.na(data$User_Count), median_User_Count, data$User_Count)
data$JP_Sales <- ifelse(is.na(data$JP_Sales), median_JP_Sales, data$JP_Sales)
data$Critic_Count <- ifelse(is.na(data$Critic_Count), median_Critic_Count, data$Critic_Count)
data$User_Score <- ifelse(is.na(data$User_Score), median_User_Score, data$User_Score)

```

```{r message=FALSE, warning=FALSE, include=TRUE}

data <- data[complete.cases(data),]
summary(data)
```

# Exploratory data analysis
# Get a new dataframe with only the numerical values
```{r message=FALSE, warning=FALSE, include=TRUE}
numeric_df <- data %>%
  select_if(is.numeric)
data_corr <- cor(numeric_df, method = "pearson")
data_cor <- subset(data_corr, select = -Year_of_Release)

# Melt the correlation matrix
data_corr_melt <- melt(data_cor)
data_corr_melt <- data_corr_melt %>% 
  filter(Var1 != "Year_of_Release" & Var2 != "Year_of_Release")

# plot the heatmaps to see the corrlation of the features
heat_map <- ggplot(data_corr_melt, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  geom_text(aes(label = round(value, 2)), size = 2) +
  scale_fill_gradient2(low = "blue", high = "red", midpoint = 0, limits = c(-1, 1)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.6, size = 5),
        axis.text.y = element_text(size = 5),
        axis.title.x = element_text(size = 7),
        axis.title.y = element_text(size = 7),
        plot.title = element_text(size = 5, hjust = 0.5),
        plot.margin = margin(t = 55, r = 55, b = 55, l =55, unit = "pt")) +
  labs(title = "video games Heatmap", x = "Features", y = "Features")

grid.arrange(heat_map, ncol = 1, widths = unit(7.5, "in"), heights = unit(6, "in"))

```

#As we can see in the graph, there is some linear correlation between school and life_expectancy, and between school and income comopsition of resources. There is also relations between GDP and percentage expenditure

```{r message=FALSE, warning=FALSE, include=TRUE}
data_corr <- cor(numeric_df, numeric_df$Global_Sales, method ="pearson")
names(data_corr) <- colnames(numeric_df)
sorted_corr_data <- sort(data_corr, decreasing = TRUE)
print(sorted_corr_data)
```
# Analysis for the catergorical features 

# what platform gets the most global sales

```{r message=FALSE, warning=FALSE, include=TRUE}


# Create a boxplot
plot <- ggplot(data, aes(x = Platform, y = Global_Sales, fill = Platform)) +
  geom_boxplot() +
  labs(title = "Boxplot of Global Sales by Platform",
       x = "Platform",
       y = "Global Sales") +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
        plot.title = element_text(size = 20, hjust = 0.5))

# Set the dimensions of the plot
options(repr.plot.width = 10, repr.plot.height = 6)

# Print the plot
print(plot)
```

```{r message=FALSE, warning=FALSE, include=TRUE}
mean_sales_by_platform <- data %>%
  group_by(Platform) %>%
  summarize(mean_global_sales = mean(Global_Sales, na.rm = TRUE))

ggplot(mean_sales_by_platform, aes(x = reorder(Platform, mean_global_sales), y = mean_global_sales)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  scale_fill_brewer(palette = "Set1")

mean_sales_by_platform
```

# group the publisher feature, so there will be less features after dummy coding (less thab 10 frequncy -> Other Publisher)
```{r message=FALSE, warning=FALSE, include=TRUE}
freq_table <- table(data$Publisher)
#ranked_table <- sort(freq_table, decreasing = TRUE)
#print(ranked_table)

#freq_table <- table(data$Publisher)
low_freq_publishers <- names(freq_table[freq_table < 10])
data$Publisher_grouped <- ifelse(data$Publisher %in% low_freq_publishers, "Other Publishers", data$Publisher)
```

```{r message=FALSE, warning=FALSE, include=TRUE}
freq_table <- table(data$Publisher_grouped)
ranked_table <- sort(freq_table, decreasing = TRUE)
print(ranked_table)

#data
```

# dummy coding for platform, genre, ratings, publishers
```{r message=FALSE, warning=FALSE, include=TRUE}

library(caret)
dummy_formula <- ~ Platform + Genre + Rating +Publisher_grouped

# create a dummyVars object
dummy_var_object <- dummyVars(dummy_formula, data = data)

# generate dummy variables using the dummyVars object
dummy_data <- predict(dummy_var_object, newdata = data)

# convert the matrix to a data frame
dummy_data <- as.data.frame(dummy_data)

# combine the original data frame with the dummy data frame
data_dummy <- cbind(data, dummy_data)
```

```{r message=FALSE, warning=FALSE, include=TRUE}
data_dummy_clean <- data_dummy %>%
  select(-Publisher, -Developer, -NA_Sales, -EU_Sales, -JP_Sales, -Other_Sales, -Platform, -Genre, -Rating, -Name, -Year_of_Release, -Publisher_grouped)
#data_dummy_clean
```

# also create a dataset without grouping the Publisher, this can be served as a evualtion tool to see if the grouping makes sence

```{r message=FALSE, warning=FALSE, include=TRUE}
dummy_formula2 <- ~ Platform + Genre + Rating +Publisher

# create a dummyVars object
dummy_var_object2 <- dummyVars(dummy_formula2, data = data)

# generate dummy variables using the dummyVars object
dummy_data2 <- predict(dummy_var_object2, newdata = data)

# convert the matrix to a data frame
dummy_data2 <- as.data.frame(dummy_data2)

# combine the original data frame with the dummy data frame
data_dummy2 <- cbind(data, dummy_data2)
```

# we created two dataframe, the first one (data_dummy_clean) we grouped the publisher together (Other publisher : Frequancy < 10), 
# the second one (data_dummy_clean2), we didn't group the publisher

```{r message=FALSE, warning=FALSE, include=TRUE}
data_dummy_clean2 <- data_dummy2 %>%
  select(-Publisher, -Developer, -NA_Sales, -EU_Sales, -JP_Sales, -Other_Sales, -Platform, -Genre, -Rating, -Name, -Year_of_Release, -Publisher_grouped)
#data_dummy_clean2

```

```{r message=FALSE, warning=FALSE, include=TRUE}
Y <- data_dummy_clean$Global_Sales
data_dummy_x <- data_dummy_clean %>%
  select(-Global_Sales)

```

# We also try to see the distrubtion of global sales, and see if we need to modify it

```{r message=FALSE, warning=FALSE, include=TRUE}
library(stats)
mu <- mean(data$Global_Sales, na.rm = TRUE)
sigma <- sd(data$Global_Sales, na.rm = TRUE)
cat("\n mu =", round(mu, 2), "and sigma =", round(sigma, 2), "\n")

# a histogram with density plot overlay
ggplot(data, aes(x = Global_Sales)) +
  geom_histogram(aes(y = ..density..), bins = 30, color = "black", fill = "lightblue", alpha = 0.7) +
  geom_density(color = "red") +
  stat_function(fun = dnorm, args = list(mean = mu, sd = sigma), color = "blue", size = 1) +
  labs(title = "Global_Sales Distribution",
       x = "Global_Sales",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  annotate("text", x = max(data$Global_Sales, na.rm = TRUE) * 0.5, y = max(density(data$Global_Sales, na.rm = TRUE)$y) * 0.85, 
           label = paste("Normal dist. (\u03BC =", round(mu, 2), "and \u03C3 =", round(sigma, 2), ")"), color = "blue")

# a QQ-plot, to see the distrubtion of the global sales, to see if that 
# follow the normal distrubution 

qqnorm(data$Global_Sales, main = "QQ-plot of Global_Sales")
qqline(data$Global_Sales, col = "blue")

```

# As we can see, the distribution of global sales is not a normal distribution, or near the normal distribution, so we may can transfrom that data later. 

# So we can do a log transfer of the dataset first to see if that will result a better solution

```{r message=FALSE, warning=FALSE, include=TRUE}
data_dummy_clean$log_Global_Sales <- log1p(data_dummy_clean$Global_Sales)
data_dummy_clean2$log_Global_Sales <- log1p(data_dummy_clean2$Global_Sales)
```

# Models
# Model 1
# Linear regression for the dataset after grouping the Publisher features: 
```{r message=FALSE, warning=FALSE, include=TRUE}

set.seed(123)
train_idx <- createDataPartition(data_dummy_clean$log_Global_Sales, p = 0.8, list = FALSE)
train_data <- data_dummy_clean[train_idx, ]
test_data <- data_dummy_clean[-train_idx, ]

# separate the target variable (Y) and the predictor variables (X)
train_Y <- train_data$log_Global_Sales
train_X <- train_data[, setdiff(names(train_data), c("Global_Sales", "log_Global_Sales"))]
test_Y <- test_data$log_Global_Sales
test_X <- test_data[, setdiff(names(test_data), c("Global_Sales", "log_Global_Sales"))]


model.lm <- train(x=train_X, y=train_Y, method = 'lm')
summary(model.lm)
pre.lm <- predict(model.lm, test_X, type = 'raw')
pre.lm <- as.vector(pre.lm)
```
# here is the reported mse and R squred value for linear regression
```{r message=FALSE, warning=FALSE, include=TRUE}

mse.lm <- mean((pre.lm-test_Y)^2)
rmse.lm <- sqrt(mean((pre.lm-test_Y)^2))
mae.lm <- mean(abs(pre.lm-test_Y))
test_r2_lm <- 1 - (sum((pre.lm - test_Y)^2) / sum((test_Y - mean(test_Y))^2))
cat("R-squared value for the test dataset (linear model):", test_r2_lm, "\n")
cat("\nMSE =", round(mse.lm, 2), "RMSE =", round(rmse.lm, 2), "MAE =", round(mae.lm, 2), "\n")
```
# scatter plot for linear regression 
```{r message=FALSE, warning=FALSE, include=TRUE}
# Generate the scatter plot
preds <- pre.lm
actual_values <- test_Y
plot(actual_values, preds, main = "Actual Sales vs. Predicted Sales", xlab = "Actual Sales", ylab = "Predicted Sales")
abline(0, 1, col = "red") # Add a 45-degree line for reference
```

# Model 2

# linear regression with a lasso term after grouping the Publisher features:
```{r message=FALSE, warning=FALSE, include=TRUE}
library(glmnet)

# convert the data to a matrix
train_X_matrix <- as.matrix(train_X)
test_X_matrix <- as.matrix(test_X)

# alpha parameter for LASSO
alpha_lasso <- 1

#  LASSO regression model
model.lasso <- cv.glmnet(train_X_matrix, train_Y, alpha = alpha_lasso)

# find the optimal lambda value
lambda_optimal <- model.lasso$lambda.min

# use the optimal lambda to fit the LASSO regression model
model.lasso_opt <- glmnet(train_X_matrix, train_Y, alpha = alpha_lasso, lambda = lambda_optimal)
```
# here is the reported mse and R squred value for LASSO regression
```{r message=FALSE, warning=FALSE, include=TRUE}
# predictions
pre.lasso <- predict(model.lasso_opt, test_X_matrix)
test_r2_lasso <- 1 - (sum((pre.lasso - test_Y)^2) / sum((test_Y - mean(test_Y))^2))
mse.lasso <- mean((pre.lasso - test_Y)^2)
rmse.lasso <- sqrt(mse.lasso)
mae.lasso <- mean(abs(pre.lasso - test_Y))
cat("R-squared value for the test dataset (LASSO model):", test_r2_lasso, "\n")
cat("\nLASSO MSE =", round(mse.lasso, 2), "RMSE =", round(rmse.lasso, 2), "MAE =", round(mae.lasso, 2), "\n")
```
# scatter plot for linear regression lasso regression
```{r message=FALSE, warning=FALSE, include=TRUE}
# Generate the scatter plot
preds <- pre.lasso
actual_values <- test_Y
plot(actual_values, preds, main = "Actual Sales vs. Predicted Sales", xlab = "Actual Sales", ylab = "Predicted Sales")
abline(0, 1, col = "red") # Add a 45-degree line for reference
```

# Model 3

# XGBoost regression after grouping the Publisher features:
```{r message=FALSE, warning=FALSE, include=TRUE}

library(xgboost)
# split the data into training (80%) and testing (20%) sets
set.seed(123)
train_idx <- createDataPartition(data_dummy_clean$log_Global_Sales, p = 0.8, list = FALSE)
train_data <- data_dummy_clean[train_idx, ]
test_data <- data_dummy_clean[-train_idx, ]

# separate the target variable (Y) and the predictor variables (X)
train_Y <- train_data$log_Global_Sales
train_X <- train_data[, setdiff(names(train_data), c("Global_Sales", "log_Global_Sales"))]
test_Y <- test_data$log_Global_Sales
test_X <- test_data[, setdiff(names(test_data), c("Global_Sales", "log_Global_Sales"))]

# convert the data to xgb.DMatrix format
# specific data type for gradient boosting regression
dtrain <- xgb.DMatrix(data = as.matrix(train_X), label = train_Y)
dtest <- xgb.DMatrix(data = as.matrix(test_X), label = test_Y)

# set parameters for the Gradient Boosting Regressor model
# 
params <- list(
  objective = "reg:squarederror",
  # use mae as the parameter defines the evaluation 
  eval_metric = "rmse",
  # learning rate
  eta = 0.1,
  # max depth of the tree is 6
  max_depth = 6,
  # 80% of training data will be used 
  subsample = 0.8,
  # fraction of the features
  colsample_bytree = 0.8
)

# train the model
set.seed(123)
model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 50,
  watchlist = list(train = dtrain, test = dtest),
  early_stopping_rounds = 5,
  verbose = 1
)
```
# print the MSE and R square for XGBoost
```{r message=FALSE, warning=FALSE, include=TRUE}
train_preds <- predict(model, dtrain)
test_preds <- predict(model, dtest)

# Calculate R-squared for training data
train_r2 <- 1 - (sum((train_preds - train_Y)^2) / sum((train_Y - mean(train_Y))^2))

# Calculate R-squared for test data
test_r2 <- 1 - (sum((test_preds - test_Y)^2) / sum((test_Y - mean(test_Y))^2))
train_mse <- mean((train_preds - train_Y)^2)

# Calculate MSE for test data
test_mse <- mean((test_preds - test_Y)^2)


# Print R-squared values
cat("R-squared value for the training dataset:", train_r2, "\n")
cat("R-squared value for the test dataset:", test_r2, "\n")
cat("Mean Squared Error for the training dataset:", train_mse, "\n")
cat("Mean Squared Error for the test dataset:", test_mse, "\n")
```


# Now we try to fine tune the hyperparameters using cross validation
# keep the parameters with the lowest mse

# tunning for XGBoost
```{r message=FALSE, warning=FALSE, include=TRUE}

eta_grid <- c(0.01, 0.1, 0.2)
max_depth_grid <- c(4, 6, 8)

best_mse <- Inf  # Initialize the best MSE to infinity
best_params <- NULL  # Initialize the best parameters to NULL

# set a random seed for reproducibility
set.seed(123)

# loop over eta and max_depth hyperparameters
for (eta in eta_grid) {
  for (max_depth in max_depth_grid) {

    # Set the current combination of hyperparameters
    params <- list(
      objective = "reg:squarederror",
      eval_metric = "rmse",
      eta = eta,
      max_depth = max_depth,
      subsample = 0.8,  # Use default value
      colsample_bytree = 0.8  # Use default value
    )

    # Perform cross-validation with the current hyperparameters
    cv_results <- xgb.cv(
      params = params,
      data = dtrain,
      nrounds = 50,
      nfold = 5,
      early_stopping_rounds = 5,
      verbose = 0  # Suppress output
    )

    # Get the MSE for the last round of cross-validation
    current_mse <- tail(cv_results$evaluation_log$test_rmse_mean, 1)

    # Check if the current MSE is better than the best MSE so far
    if (current_mse < best_mse) {
      best_mse <- current_mse
      best_params <- params
    }

  }
}

```
# report the best model: 
```{r message=FALSE, warning=FALSE, include=TRUE}
set.seed(123)
best_model <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = 50,
  watchlist = list(train = dtrain, test = dtest),
  early_stopping_rounds = 5,
  verbose = 1
)

```
# As we can see the MSE for each training round for both training and test set, and compare to
# the model before hyparameter tunnig, this result in a lower mse for both training and testing set 

# print the MSE and R squared for the best XGBoost model:
```{r message=FALSE, warning=FALSE, include=TRUE}
train_preds_best <- predict(best_model, dtrain)
test_preds_best <- predict(best_model, dtest)

# Calculate R-squared for training data
train_r2_best <- 1 - (sum((train_preds_best - train_Y)^2) / sum((train_Y - mean(train_Y))^2))

# Calculate R-squared for test data
test_r2_best <- 1 - (sum((test_preds_best - test_Y)^2) / sum((test_Y - mean(test_Y))^2))

# Calculate MSE for training data
train_mse_best <- mean((train_preds_best - train_Y)^2)

# Calculate MSE for test data
test_mse_best <- mean((test_preds_best - test_Y)^2)

# Print R-squared and MSE values
cat("R-squared value for the training dataset (best_model):", train_r2_best, "\n")
cat("R-squared value for the test dataset (best_model):", test_r2_best, "\n")
cat("Mean Squared Error for the training dataset (best_model):", train_mse_best, "\n")
cat("Mean Squared Error for the test dataset (best_model):", test_mse_best, "\n")
```
# scattor pkot for XGBoost after group the publisher
```{r message=FALSE, warning=FALSE, include=TRUE}
preds <- predict(best_model, dtest)
# extract the actual values from the dtest matrix
actual_values <- getinfo(dtest, "label")
# scatter plot comparing the actual values to the predicted values
plot(actual_values, preds, main = "actual sales", xlab = "actual sales", ylab = "predict sales")
abline(0, 1, col = "red") # Add a 45-degree line for reference
```
# Now we try to use the dataframe without the grouping of publisher, to see if that changes the result
# XGBoost without grouping the publishers
```{r message=FALSE, warning=FALSE, include=TRUE}

set.seed(123)
train_idx2 <- createDataPartition(data_dummy_clean2$log_Global_Sales, p = 0.8, list = FALSE)
train_data2 <- data_dummy_clean2[train_idx, ]
test_data2 <- data_dummy_clean2[-train_idx, ]
# separate the target variable (Y) and the predictor variables (X)
train_Y2 <- train_data2$log_Global_Sales
train_X2 <- train_data2[, setdiff(names(train_data2), c("Global_Sales", "log_Global_Sales"))]
test_Y2 <- test_data2$log_Global_Sales
test_X2 <- test_data2[, setdiff(names(test_data2), c("Global_Sales", "log_Global_Sales"))]

# convert the data to xgb.DMatrix format
# specific data type for gradient boosting regression
dtrain2 <- xgb.DMatrix(data = as.matrix(train_X2), label = train_Y2)
dtest2 <- xgb.DMatrix(data = as.matrix(test_X2), label = test_Y2)
```

```{r message=FALSE, warning=FALSE, include=TRUE}
set.seed(123)
best_model <- xgb.train(
  params = best_params,
  data = dtrain2,
  nrounds = 50,
  watchlist = list(train = dtrain2, test = dtest2),
  early_stopping_rounds = 5,
  verbose = 1
)

```
```{r message=FALSE, warning=FALSE, include=TRUE}
best_params


```


```{r message=FALSE, warning=FALSE, include=TRUE}
train_preds_best <- predict(best_model, dtrain2)
test_preds_best <- predict(best_model, dtest2)

# Calculate R-squared for training data
train_r2_best <- 1 - (sum((train_preds_best - train_Y)^2) / sum((train_Y - mean(train_Y))^2))

# Calculate R-squared for test data
test_r2_best <- 1 - (sum((test_preds_best - test_Y)^2) / sum((test_Y - mean(test_Y))^2))

# Calculate MSE for training data
train_mse_best <- mean((train_preds_best - train_Y)^2)

# Calculate MSE for test data
test_mse_best <- mean((test_preds_best - test_Y)^2)

# Print R-squared and MSE values
cat("R-squared value for the training dataset (best_model):", train_r2_best, "\n")
cat("R-squared value for the test dataset (best_model):", test_r2_best, "\n")
cat("Mean Squared Error for the training dataset (best_model):", train_mse_best, "\n")
cat("Mean Squared Error for the test dataset (best_model):", test_mse_best, "\n")
```

# As we can see in the above result, the changes in the group of publisher doesnot have a strong impact on the model performance, so the grouping method works
# Scatter plot for not grouping 
```{r message=FALSE, warning=FALSE, include=TRUE}
preds <- predict(best_model, dtest2)
# extract the actual values from the dtest matrix
actual_values <- getinfo(dtest2, "label")
# scatter plot comparing the actual values to the predicted values
plot(actual_values, preds, main = "actual sales", xlab = "actual sales", ylab = "predict sales")
abline(0, 1, col = "red") # Add a 45-degree line for reference
```


# We also try to fit model to predict the critic score for games using the features in the dataset
```{r message=FALSE, warning=FALSE, include=TRUE}
# Split the data into training and testing sets
train_indice <- createDataPartition(data_dummy_clean$Critic_Score, p = 0.8, list = FALSE)
train_d <- data_dummy_clean[train_indice, ]
test_d <- data_dummy_clean[-train_indice, ]

# Create a formula to predict Critic_Score
formula <- Critic_Score ~ .

# Fit a linear regression model
model <- lm(formula, data = train_d)

# Summarize the model
summary(model)

# Make predictions on the test set
predictions <- predict(model, newdata = test_d)

# Calculate performance metrics
mse <- mean((test_d$Critic_Score - predictions)^2)
rmse <- sqrt(mse)
mae <- mean(abs(test_d$Critic_Score - predictions))

cat("\nMSE =", round(mse, 2), "RMSE =", round(rmse, 2), "MAE =", round(mae, 2), "\n")

# Plot actual vs predicted values
ggplot(test_data, aes(x = Critic_Score, y = predictions)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  labs(title = "Actual vs Predicted Critic Score",
       x = "Actual Critic Score",
       y = "Predicted Critic Score") +
  theme_minimal()
```

